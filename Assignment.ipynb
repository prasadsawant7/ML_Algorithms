{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prasadsawant7/ML_Algorithms/blob/main/Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "8e35212f",
      "metadata": {
        "id": "8e35212f"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import silhouette_score\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "753ebf7f",
      "metadata": {
        "id": "753ebf7f"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Mall_Customers.csv')\n",
        "# Gender is encoded to the 0 and 1 value in order to normalize the dataset\n",
        "df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would like to express our gratitude to **Vijay Choudhary** for providing the **Mall Customer Segmentation Data** on **Kaggle**. This dataset has been instrumental in our assignment, allowing us to explore and analyze customer segmentation using the K-means clustering algorithm. We sincerely appreciate **Vijay Choudhary's** efforts in collecting and sharing this valuable dataset. The dataset can be accessed at: [Mall Customer Segmentation Data](https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python)."
      ],
      "metadata": {
        "id": "OggZJ9J2hER9"
      },
      "id": "OggZJ9J2hER9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking whether there are null values or not in the dataset.\n",
        "print(df.isnull().sum())\n",
        "# If null values exists then fill those values with mean values of the dataset.\n",
        "df = df.fillna(df.mean())"
      ],
      "metadata": {
        "id": "Ccgkepr07oUf"
      },
      "id": "Ccgkepr07oUf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing the dataset on the scale between 0 and 1 using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaler.fit(df[['Age']])\n",
        "df.Age = scaler.transform(df[['Age']])\n",
        "\n",
        "scaler.fit(df[['Annual Income (k$)']])\n",
        "df['Annual Income (k$)'] = scaler.transform(df[['Annual Income (k$)']])\n",
        "\n",
        "scaler.fit(df[['Spending Score (1-100)']])\n",
        "df['Spending Score (1-100)'] = scaler.transform(df[['Spending Score (1-100)']])\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "Tum3dkMD8OHf"
      },
      "id": "Tum3dkMD8OHf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "834f7c34",
      "metadata": {
        "id": "834f7c34"
      },
      "outputs": [],
      "source": [
        "# Visualizing the dataset before applying KMeans\n",
        "x = df['Annual Income (k$)']\n",
        "y = df['Spending Score (1-100)']\n",
        "age = df['Age']\n",
        "gender = df['Gender']\n",
        "\n",
        "plt.scatter(x, y, s=age*10, alpha=0.6)\n",
        "plt.xlabel('Annual Income (Normalized)')\n",
        "plt.ylabel('Spending Score (Normalized)')\n",
        "plt.title('Scatter Plot of Annual Income vs. Spending Score with Age and Gender')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying KMeans algorithm on the data and assuming the K value or no. of clusters as 3.\n",
        "km = KMeans(n_clusters=3)\n",
        "km.n_init = 10\n",
        "y_predicted = km.fit_predict(df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']])\n",
        "df['cluster'] = y_predicted\n",
        "\n",
        "# Evaluating the quality of the clustering results\n",
        "silhouette_avg = silhouette_score(df[['Annual Income (k$)', 'Spending Score (1-100)']], y_predicted)\n",
        "print(\"Silhouette Score:\", silhouette_avg)\n",
        "\n",
        "inertia = km.inertia_\n",
        "print(\"Inertia:\", inertia)\n",
        "\n",
        "'''\n",
        "Visualizing the dataset:\n",
        "\n",
        "X-Axis: Annual Income (k$)\n",
        "\n",
        "Y-Axis: Spending Score (1-100)\n",
        "\n",
        "Multiplying the 'Age' values by 10 to visually emphasize the importance or \n",
        "significance of the 'Age' feature in relation to the 'Annual Income' and 'Spending Score' features. \n",
        "By increasing the size of the markers proportional to the 'Age' values, \n",
        "the plot can visually highlight the impact of age on the clustering results.\n",
        "'''\n",
        "df1 = df[df.cluster==0]\n",
        "df2 = df[df.cluster==1]\n",
        "df3 = df[df.cluster==2]\n",
        "\n",
        "plt.scatter(df1['Annual Income (k$)'], df1['Spending Score (1-100)'], color='green', s=df1['Age']*10, alpha=0.6)\n",
        "plt.scatter(df2['Annual Income (k$)'], df2['Spending Score (1-100)'], color='red', s=df2['Age']*10, alpha=0.6)\n",
        "plt.scatter(df3['Annual Income (k$)'], df3['Spending Score (1-100)'], color='black', s=df3['Age']*10, alpha=0.6)\n",
        "\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')"
      ],
      "metadata": {
        "id": "Ukm5FeBoGzhY"
      },
      "id": "Ukm5FeBoGzhY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking 9 Sum of Sqaured Errors values in order to find the value of K using Elbow Technique\n",
        "k_rng = range(1, 10)\n",
        "sse = []\n",
        "\n",
        "for k in k_rng:\n",
        "  km = KMeans(n_clusters=k)\n",
        "  km.n_init = 10\n",
        "  km.fit(df[['Annual Income (k$)', 'Spending Score (1-100)']])\n",
        "  sse.append(km.inertia_)\n",
        "\n",
        "print(sse)\n",
        "\n",
        "plt.xlabel('K')\n",
        "plt.ylabel('Sum of Squared Errors')\n",
        "plt.plot(k_rng, sse)"
      ],
      "metadata": {
        "id": "ye53X8Uw6thA"
      },
      "id": "ye53X8Uw6thA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Elbow point is at the 5 point on the x-axis of the plot\n",
        "km = KMeans(n_clusters=5)\n",
        "km.n_init = 10\n",
        "y_predicted = km.fit_predict(df[['Annual Income (k$)', 'Spending Score (1-100)']])\n",
        "df['cluster'] = y_predicted\n",
        "\n",
        "# Evaluating the quality of the clustering results\n",
        "silhouette_avg = silhouette_score(df[['Annual Income (k$)', 'Spending Score (1-100)']], y_predicted)\n",
        "print(\"Silhouette Score:\", silhouette_avg)\n",
        "\n",
        "inertia = km.inertia_\n",
        "print(\"Inertia:\", inertia)\n",
        "\n",
        "# Visualizing the dataset before applying KMeans\n",
        "df1 = df[df.cluster==0]\n",
        "df2 = df[df.cluster==1]\n",
        "df3 = df[df.cluster==2]\n",
        "df4 = df[df.cluster==3]\n",
        "df5 = df[df.cluster==4]\n",
        "\n",
        "plt.scatter(df1['Annual Income (k$)'], df1['Spending Score (1-100)'], color='green', s=df1['Age']*10, alpha=0.6)\n",
        "plt.scatter(df2['Annual Income (k$)'], df2['Spending Score (1-100)'], color='red', s=df2['Age']*10, alpha=0.6)\n",
        "plt.scatter(df3['Annual Income (k$)'], df3['Spending Score (1-100)'], color='black', s=df3['Age']*10, alpha=0.6)\n",
        "plt.scatter(df4['Annual Income (k$)'], df4['Spending Score (1-100)'], color='blue', s=df4['Age']*10, alpha=0.6)\n",
        "plt.scatter(df5['Annual Income (k$)'], df5['Spending Score (1-100)'], color='orange', s=df5['Age']*10, alpha=0.6)\n",
        "\n",
        "plt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:,1], color='purple', marker='*', label='centroid')\n",
        "\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "zJclbD6g9ait"
      },
      "id": "zJclbD6g9ait",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Strengths of K-means algorithm in the context of the Mall Customers dataset:**\n",
        "\n",
        "1. Interpretability: K-means provides interpretable results as the clusters are represented by their centroids. In the case of the Mall Customers dataset, the algorithm can identify distinct groups of customers based on their annual income and spending score. This can help in understanding customer segmentation and making targeted marketing strategies.\n",
        "\n",
        "2. Scalability: K-means is computationally efficient and can handle large datasets with a reasonable number of clusters. The Mall Customers dataset may contain a significant number of records, and K-means can efficiently process and cluster the data.\n",
        "\n",
        "3. Speed: K-means is a fast algorithm, making it suitable for large-scale applications. With a relatively low-dimensional dataset like Mall Customers, K-means can quickly converge and provide clustering results in a timely manner.\n",
        "\n",
        "4. Flexibility in cluster assignment: K-means assigns each data point to only one cluster, allowing for clear separation of customers into distinct groups based on their spending behavior. This can assist in targeted marketing campaigns tailored to specific customer segments.\n",
        "\n",
        "\n",
        "**Limitations of K-means algorithm in the context of the Mall Customers dataset:**\n",
        "\n",
        "1. Determining the number of clusters (K): Selecting the optimal value of K is crucial for effective clustering. In the case of the Mall Customers dataset, determining the appropriate number of customer segments may require additional analysis and domain knowledge. An incorrect choice of K could lead to suboptimal clustering results.\n",
        "\n",
        "2. Sensitivity to initial centroid selection: K-means is sensitive to the initial placement of centroids. Depending on the initial configuration, the algorithm may converge to different solutions. Multiple runs with different initializations can be used to mitigate this issue, but it increases computational complexity.\n",
        "\n",
        "3. Assumption of equal variance and circular clusters: K-means assumes that clusters have the same variance and are circular in shape. This assumption may not hold for the Mall Customers dataset, as different customer segments may have varying spending behaviors and income distributions. Non-circular or non-convex clusters in the data may lead to suboptimal clustering results.\n",
        "\n",
        "4. Handling outliers: K-means can be affected by the presence of outliers, such as customers with exceptionally high or low spending scores. Outliers can influence the position of centroids, leading to inaccurate cluster assignments.\n",
        "\n",
        "5. Limitations with categorical variables: K-means is a distance-based algorithm and works best with numerical variables. In the Mall Customers dataset, if categorical variables like gender are included, a suitable transformation or alternative clustering algorithm may be required to handle them effectively.\n",
        "\n",
        "In conclusion, while the K-means algorithm has strengths in interpretability, scalability, and speed, it is important to consider its limitations, particularly in determining the number of clusters and assumptions about the data's distribution and shape. These limitations should be taken into account when analyzing the Mall Customers dataset and making decisions based on the clustering results."
      ],
      "metadata": {
        "id": "lJL32Gxdexi4"
      },
      "id": "lJL32Gxdexi4"
    },
    {
      "cell_type": "code",
      "source": [
        "# Extensions (A): Random Initialization & KMeans++\n",
        "# Random Initialization\n",
        "\n",
        "# By passing init=\"random\" we can use random initialization strategy on the KMeans\n",
        "km = KMeans(n_clusters=5, init=\"random\")\n",
        "km.n_init = 10\n",
        "y_predicted = km.fit_predict(df[['Annual Income (k$)', 'Spending Score (1-100)']])\n",
        "df['cluster'] = y_predicted\n",
        "\n",
        "# Evaluating the quality of the clustering results\n",
        "silhouette_avg = silhouette_score(df[['Annual Income (k$)', 'Spending Score (1-100)']], y_predicted)\n",
        "print(\"Silhouette Score:\", silhouette_avg)\n",
        "\n",
        "inertia = km.inertia_\n",
        "print(\"Inertia:\", inertia)\n",
        "\n",
        "# Visualizing the dataset before applying KMeans\n",
        "df1 = df[df.cluster==0]\n",
        "df2 = df[df.cluster==1]\n",
        "df3 = df[df.cluster==2]\n",
        "df4 = df[df.cluster==3]\n",
        "df5 = df[df.cluster==4]\n",
        "\n",
        "plt.scatter(df1['Annual Income (k$)'], df1['Spending Score (1-100)'], color='green', s=df1['Age']*10, alpha=0.6)\n",
        "plt.scatter(df2['Annual Income (k$)'], df2['Spending Score (1-100)'], color='red', s=df2['Age']*10, alpha=0.6)\n",
        "plt.scatter(df3['Annual Income (k$)'], df3['Spending Score (1-100)'], color='black', s=df3['Age']*10, alpha=0.6)\n",
        "plt.scatter(df4['Annual Income (k$)'], df4['Spending Score (1-100)'], color='blue', s=df4['Age']*10, alpha=0.6)\n",
        "plt.scatter(df5['Annual Income (k$)'], df5['Spending Score (1-100)'], color='orange', s=df5['Age']*10, alpha=0.6)\n",
        "\n",
        "plt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:,1], color='purple', marker='*', label='centroid')\n",
        "\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "EqRINTtMRrEe"
      },
      "id": "EqRINTtMRrEe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KMeans++\n",
        "\n",
        "# By passing init=\"k-means++\" we can use KMeans++ strategy on the KMeans\n",
        "km = KMeans(n_clusters=5, init='k-means++')\n",
        "km.n_init = 10\n",
        "y_predicted = km.fit_predict(df[['Annual Income (k$)', 'Spending Score (1-100)']])\n",
        "df['cluster'] = y_predicted\n",
        "\n",
        "# Evaluating the quality of the clustering results\n",
        "silhouette_avg = silhouette_score(df[['Annual Income (k$)', 'Spending Score (1-100)']], y_predicted)\n",
        "print(\"Silhouette Score:\", silhouette_avg)\n",
        "\n",
        "inertia = km.inertia_\n",
        "print(\"Inertia:\", inertia)\n",
        "\n",
        "# Visualizing the dataset before applying KMeans\n",
        "df1 = df[df.cluster==0]\n",
        "df2 = df[df.cluster==1]\n",
        "df3 = df[df.cluster==2]\n",
        "df4 = df[df.cluster==3]\n",
        "df5 = df[df.cluster==4]\n",
        "\n",
        "plt.scatter(df1['Annual Income (k$)'], df1['Spending Score (1-100)'], color='green', s=df1['Age']*10, alpha=0.6)\n",
        "plt.scatter(df2['Annual Income (k$)'], df2['Spending Score (1-100)'], color='red', s=df2['Age']*10, alpha=0.6)\n",
        "plt.scatter(df3['Annual Income (k$)'], df3['Spending Score (1-100)'], color='black', s=df3['Age']*10, alpha=0.6)\n",
        "plt.scatter(df4['Annual Income (k$)'], df4['Spending Score (1-100)'], color='blue', s=df4['Age']*10, alpha=0.6)\n",
        "plt.scatter(df5['Annual Income (k$)'], df5['Spending Score (1-100)'], color='orange', s=df5['Age']*10, alpha=0.6)\n",
        "\n",
        "plt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:,1], color='purple', marker='*', label='centroid')\n",
        "\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "ZbSS8ZRiSnb9"
      },
      "id": "ZbSS8ZRiSnb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extensions (B): Hierarchical Clustering & DBSCAN\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "df = pd.read_csv('Mall_Customers.csv')\n",
        "df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})\n",
        "\n",
        "scaler.fit(df[['Age']])\n",
        "df.Age = scaler.transform(df[['Age']])\n",
        "\n",
        "scaler.fit(df[['Annual Income (k$)']])\n",
        "df['Annual Income (k$)'] = scaler.transform(df[['Annual Income (k$)']])\n",
        "\n",
        "scaler.fit(df[['Spending Score (1-100)']])\n",
        "df['Spending Score (1-100)'] = scaler.transform(df[['Spending Score (1-100)']])\n",
        "\n",
        "x = df['Annual Income (k$)']\n",
        "y = df['Spending Score (1-100)']\n",
        "age = df['Age']\n",
        "gender = df['Gender']"
      ],
      "metadata": {
        "id": "Tjy4KP7gYO-9"
      },
      "id": "Tjy4KP7gYO-9",
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hierarchical Clustering\n",
        "hierarchical = AgglomerativeClustering(n_clusters=5)\n",
        "h_labels = hierarchical.fit_predict(df[['Annual Income (k$)', 'Spending Score (1-100)']])\n",
        "\n",
        "# Visualize Hierarchical Clustering\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(x, y, s=age*10, alpha=0.6, c=h_labels, cmap='rainbow')\n",
        "plt.title('Hierarchical Clustering')\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "\n",
        "# DBSCAN\n",
        "dbscan = DBSCAN(eps=0.3, min_samples=5)\n",
        "d_labels = dbscan.fit_predict(df[['Annual Income (k$)', 'Spending Score (1-100)']])\n",
        "\n",
        "# Visualize DBSCAN\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(x, y, s=age*10, alpha=0.6, c=d_labels, cmap='rainbow')\n",
        "plt.title('DBSCAN')\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N6PUoj71Vjxi"
      },
      "id": "N6PUoj71Vjxi",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}